<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[hadoop安装和基本使用]]></title>
    <url>%2F2018%2F02%2F07%2Fhadoop-install-use%2F</url>
    <content type="text"><![CDATA[Hadoop安装创建hadoop用户1useradd -m hadoop -s /bin/bash 安装java环境 如果是系统自带的java，请先卸载： 12rpm -qa | grep jdkrpm -e --nodeps XXXX #XXXX是上一条命令的查询结构 到Oracle官网下载jdk，并安装(这里下载的是.tar.gz版) 1234mkdir /usr/java/mv jdk-8u161-linux-x64.tar.gz /usr/java/tar zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161/ jdk1.8 编辑配置文件，配置环境变量 12345678vim /etc/profileJAVA_HOME=/usr/java/jdk1.8CLASSPATH=$JAVA_HOME/lib/PATH=$PATH:$JAVA_HOME/binexport PATH JAVA_HOME CLASSPATHsource /etc/profile 安装Hadoop2从hadoop的官网下载已经编译好的(binary)hadoop压缩包，在这里使用的是hadoop2.8.3版本。 123cd /home/hadooptar -zxvf hadoop-2.8.3.tar.gzmv hadoop-2.8.3 hadoop 修改配置文件，添加环境变量 1234567suvim /etc/profileexport HADOOP_HOME=/home/hadoop/hadoopexport PATH=.:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATHsource /etc/profile Hadoop配置在/home/hadoop/目录下，建立tmp、hdfs/name、hdfs/data目录123456$ cd /home/hadoop$ mkdir tmp$ mkdir hdfs$ cd hdfs/$ mkdir data$ mkdir name 修改hadoop的配置文件 配置hadoop-env.sh和yarn-env.sh 123456789$ cd /home/hadoop/hadoop/etc/hadoop$ vim hadoop-env.sh#修改export JAVA_HOMEexport JAVA_HOME=/usr/java/jdk1.8$ vim yarn-env.sh#修改export JAVA_HOMEexport JAVA_HOME=/usr/java/jdk1.8 配置core-site.xml 其中fs.default.name是HDFS的URI，hadoop.tmp.dir是namenode上本地的hadoop临时文件夹 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/tmp&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置hdfs-site.xml 其中dfs.name.dir是namenode上存储hdfs名字空间元数据，dfs.data.dir是namenode上数据块的物理存储位置，dfs.replication是副本的个数，默认为3，一般小于datanode的机器数量。 12345678910111213141516&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置mapred-site.xml 注意，默认文件夹中并没有这个文件，而是有一个mapred-site.xml.template，可以将该文件复制并重命名 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 配置yarn-site.xml 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; Hadoop启动格式化namenode1$ ./bin/hdfs namenode -format 启动NameNode和DataNode的守护进程1$ ./sbin/start-dfs.sh 启动ResourceManager和NodeManager的守护进程1$ ./sbin/start-yarn.sh 验证启动执行jps命令 免密登陆每次在启动或者停止hadoop是都需要输入密码进行验证，此时可以设置免密登陆： 安装ssh服务 1$ yum install -y openssh-server openssh-clients 进入用户目录，生成密钥 123456$ cd ~$ cd .ssh/$ ssh-keygen -t rsa (然后一路回车)$ cp id_rsa.pub authorized_keys$ ssh localhost #如果此时不提示任何错误，则表明设置成功 Hadoop集群安装安装3台机器 安装3个虚拟机，主机名分别为hadoop1，hadoop2和hadoop3，对应的ip分别为192.168.17.133,192.168.17.134以及192.168.17.135。 修改机器名123hostnamectl set-hostname hadoop1hostnamectl set-hostname hadoop2hostnamectl set-hostname hadoop3 修改/etc/hosts文件123192.168.17.133 hadoop1192.168.17.134 hadoop2192.168.17.135 hadoop3 免密登陆123456$ cd ~$ cd .ssh/$ ssh-keygen -t rsa (然后一路回车)$ cp id_rsa.pub authorized_keys 然后修改authorized_keys文件，将三台机器的文件内容合并，然后复制到每台机器中 配置Hadoop在hadoop1机器中执行以下命令： 12345mkdir /home/hadoop/tmp mkdir /home/hadoop/var mkdir /home/hadoop/hdfs mkdir /home/hadoop/hdfs/name mkdir /home/hadoop/hdfs/data 修改core-site.xml文件： 1234567891011&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/tmp&lt;/value&gt; &lt;description&gt;Abase for other temporary directories.&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://hadoop1:9000&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改hadoop-env.sh文件： 略 修改hdfs-site.xml文件： 123456789101112131415161718&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/hdfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改mapred-site.xml文件： 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;hadoop1:49001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapred.local.dir&lt;/name&gt; &lt;value&gt;/home/hadoop/var&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改slaves文件： hadoop2 hadoop3 修改yarn-site.xml文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;hadoop1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the applications manager interface in the RM.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the scheduler interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The http address of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The https adddress of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.https.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;description&gt;The address of the RM admin interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt; &lt;value&gt;2048&lt;/value&gt; &lt;discription&gt;每个节点可用内存,单位MB,默认8182MB&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt; &lt;value&gt;2.1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;2048&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 启动hadoop略 测试hadoop在浏览器访问 http://192.168.17.133:50070 以及 http://192.168.17.133:8088/]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HEXO安装与使用]]></title>
    <url>%2F2018%2F02%2F04%2Fhexo_install_use%2F</url>
    <content type="text"><![CDATA[nodejs安装 通过EPEL的方式进行安装 12345678# 安装epelyum install -y epel-releaseyum repolist# 安装nodeyum install -y nodejsnode --versionyum install npm hexo安装1npm install hexo-cli -g 快速新建一个博客系统 1234hexo init blogcd blognpm installhexo server hexo常用命令123456# 清空缓存hexo clean# 生成静态网页hexo g# 启动hexo服务，默认端口为4000hexo s 安装NEXT主题 资源链接 https://github.com/iissnan/hexo-theme-next 安装方法 12345$ cd hexo$ ls_config.yml node_modules package.json public scaffolds source themes$ mkdir themes/next$ curl -s https://api.github.com/repos/iissnan/hexo-theme-next/releases/latest | grep tarball_url | cut -d &apos;&quot;&apos; -f 4 | wget -i - -O- | tar -zx -C themes/next --strip-components=1 NEXT的相关配置 对于整个项目，有一个站点配置文件_config.yml，该文件位于根目录下，在本项目中位于/root/blog目录下，对于每个主题，都有一个主题的配置文件_config.yml，位于每个主题的根目录下，在本项目中位于/root/blog/themes/next目录下： 1234567$ ls /root/blog/_config.yml node_modules public sourcedb.json package.json scaffolds themes$ ls /root/blog/themes/next/bower.json gulpfile.coffee layout package.json README.md source_config.yml languages LICENSE README.cn.md scripts test 添加分类标签 如果需要给首页添加分页，首先修改主题配置文件，将menu下的about前的#去除： 123456789menu: home: / #tags: /tags/ || tags categories: /categories/ archives: /archives/ about: /about/ #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 然后在source目录下新建一个categories文件夹，并在该文件夹中添加一个index.md文件 123$ cd /root/blog/source$ mkdir categories/$ vim index.md 在文件中添加以下内容 123456---title: 文章分类date: 日期type: &quot;categories&quot;comments: false--- 然后在文件的头部添加以下内容： 12345---title: Hello Worldcategories: - test--- 添加动态背景 打开 next/layout/_layout.swig在&lt;/body&gt;之前添加代码(注意不要放在&lt;/head&gt;的后面)： 123&#123;% if theme.canvas_nest %&#125;&lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js&quot;&gt;&lt;/script&gt;&#123;% endif %&#125; 修改主题配置文件，将canvas_nest修改为true 1canvas_nest: true 添加更新时间 修改语言配置文件/themes/next/languages/zh_Hans.yml，在post下添加以下内容： 12post: updated: 更新于 修改主题配置文件/themes/next/_config.yml 1updated_at: true 写文章的时候可以直接在文章开头设置更新时间 1modified: 添加站内搜索安装hexo-generator-search 在站点的根目录下执行以下命令： 1npm install hexo-generator-search --save 安装 hexo-generator-searchdb 在站点的根目录下执行以下命令： 1npm install hexo-generator-searchdb --save 启用搜索 编辑站点配置文件，新增以下内容到最后： 12345search: path: search.xml field: post format: html limit: 10000 编辑主题配置文件，将local_search下的enable改为true： 12local_search: enable: true 上传代码到github注册Github的账号略 创建Repository创建的时候需要注意Repository的名字。例如我的Github账号是pchad321，那么应该创建的Repository的名字为：pchad321.github.io 修改配置文件 进入刚刚创建的Repository，复制Repository的连接，例如https://github.com/pchad321/pchad321.github.io.git 修改站点配置文件 12345deploy: type: git repo: https://github.com/pchad321/pchad321.github.io.git branch: master message: &apos;updated at:&#123;&#123;now(&quot;YYYY-MM-DD HH/mm/ss&quot;)&#125;&#125;&apos; 设置SSH keys 配置本机全局git环境 12git config --global user.email &quot;you@example.com&quot;git config --global user.name &quot;Your Name&quot; 生成SSH密钥 1234# -C后面是github上的用户邮箱地址ssh-keygen -t rsa -C you@126.com# 然后一路回车 将SSH密钥添加到github中 1less ~/.ssh/id_rsa.pub 复制出现的一堆密码，然后在github的SSH and GPG keys中粘贴这一段密码 设置的验证 在本地输入以下代码： 1ssh -T git@github.com 如果在最后出现了你配置的用户名，说明配置成功 提交代码到github上 12hexo generatehexo deploy 在提交代码时可能会出现ERROR Deployer not found: git的错误，此时只需要运行以下命令 1npm install --save hexo-deployer-git 将Hexo的源码备份到Github分支里面上传到分支里存储，修改本地的时候先上传存储，再发布。更换电脑的时候再下载下来源文件 12345$ git init$ git remote add origin git@github.com:username/username.github.io.git$ git add .$ git commit -m &quot;blog&quot;$ git push origin master:Hexo-Blog 在本地写好博文后，可以先执行： 123$ git add .$ git commit -m &quot;blog&quot;$ git push origin master:Hexo-Blog]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>HEXO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的shell编程]]></title>
    <url>%2F2018%2F02%2F04%2FLinux-shell%2F</url>
    <content type="text"><![CDATA[创建shell脚本文件在创建shell脚本文件时，必须在文件的第一行指定要使用的shell。其格式为 #!/bin/bash 注意：shell只会去处理第一行注释行，并不会处理其他的注释行。 创建shell脚本文件后，给文件添加执行权限 chmod u+x filename 如果想把脚本中的文本字符串和命令输出显示在同一行中，可以用echo语句的-n参数 echo -n “The time and date are: “ date 使用等号将值赋给用户变量时，在变量、等号和值之间不能出现空格。 testing=`date` testing=$(date) 引用一个变量值时需要使用$，而引用变量来对其进行赋值时则不要使用$： value1=10 value2=$value1 # 注意：没有使用$，shell会将变量名解释成普通的文本字符串。 命令替换有两种方法可以将命令输出赋给变量： 反引号字符`` $()格式 123456testing=`date`testing=$(date)echo &quot;The date and time are: &quot; $testingtoday=$(date +%y%m%d)ls /usr/bin -al &gt; log.$today 重定向重定向包括输出重定向&gt; &gt;&gt;以及输入重定向&lt; &lt;&lt; 内联输入重定向 执行数学运算expr命令12expr 1 + 56 使用方括号如果需要将一个数学运算结果赋给某个变量，可以用美元符和方括号： 1234var1=100var2=50var3=30var4=$[$var1 * ($var3 - $var2)] 需要注意的是，bash shell数学运算符只支持整数运算。 浮点解决方案在脚本中使用bc，基本格式如下： variable=$(echo “options; expression” | bc) 123var1=20var2=3.14159var3=$(echo &quot;scale=4; $var1 * var2&quot; | bc) 1234567891011121314var1=10.46var2=43.67var3=33.2var4=71var5=$(bc &lt;&lt; EOFscale = 4a1 = ($var1 * $var2)b1 = ($var3 * $var4)a1 + b1EOF)echo $var5 退出脚本退出状态码的查看$? 状态码 描述 0 命令成功结束 1 通用未知错误 2 误用Shell命令 126 命令不可执行 127 没找到命令 128 无效退出参数 128+x Linux信号x的严重错误 130 命令通过Ctrl+C控制码越界 255 退出码越界 exit命令 结构化命令if-then123if command; then commandsfi 123if pwd; then echo &quot;It worked&quot;fi if-then-else123456if commandthen commandselse commandsfi 嵌套if1234567891011if command1then commandselse if command2 then more commands else more commands fifi 1234567if command1then commandselif command2then more commandsfi test命令如果test命令中列出的条件成立，test命令就会退出并返回退出状态码0。 test condition 或者可以用在if-then语句中 1234if test conditionthen commandsfi 也可以使用方括号进行测试 1234if [ condition ]then commandsfi 数值比较 比较 描述 n1 -eq n2 检查n1是否等于n2 n1 -ge n2 检查n1是否大于等于n2 n1 -gt n2 检查n1是否大于n2 n1 -le n2 检查n1是否小于等于n2 n1 -lt n2 检查n1是否小于n2 n1 -ne n2 检查n1是否不等于n2 字符串比较 比较 描述 str1 = str2 检查字符串是否相同 str1 != str2 检查字符串是否不同 str1 &lt; str2 检查str1是否比str2大 str1 > str2 检查str1是否比str2小 -n str1 检查str1的长度是否非0 -z str1 检查str1的长度是否为0 需要注意的是，大于号和小于号在使用时需要转义 文件比较 比较 描述 -e file 如果file存在，则为真 -d file 如果file存在并为目录，则为真 -f file 如果file为常规文件，则为真 -r file 如果file存在并可读，则为真 -s file 如果file存在并非空，则为真 -w file 如果file存在并可写，则为真 -x file 如果file存在并可执行，则为真 -O file 如果file存在并属于当前用户，则为真 -G file 如果file存在并且默认组与当前用户相同，则为真 file1 -nt file2 如果file1比file2新，则为真 file1 -ot file2 如果file1比file2旧，则为真 复合条件测试if-then可以用&amp;&amp;和||来组合测试 if-then的高级特性使用双括号双括号命令允许你在比较过程中使用高级数学表达式。其格式如下： ((expression)) 双括号命令符号包括以下：val++，val–，++val，–val，!，~，**(幂运算)，&lt;&lt;，&gt;&gt;，&amp;，|，&amp;&amp;，|| 使用双方括号双方括号命令提供了针对字符串比较的高级特性。其格式如下： [[expression]] 1if [[ $USER == r* ]] case命令12345case variable inpattern1 | pattern2) commands1;;pattern3) commands2;;*) default commands;;esac for命令1234for var in listdo commandsdone for循环假定每个值都是用空格分割的。可以使用内部字段分隔符IFS来自定义分隔符，例如 IFS=$’\n’ IFS=$’\n’:;” C语言分隔的for命令命令格式： for (( variable assignment ; condition ; iteration process )) while命令while命令的基本格式： 1234while test commanddo other commandsdone until命令until命令和while命令正好相反，只有测试命令的退出状态码不为0，bash shell才会执行循环中列出的命令。 命令格式： 1234until test commandsdo other commandsdone 循环处理文件数据需要使用嵌套循环以及修改IFS环境变量 1234567891011121314IFS.OLD=$IFSIFS=$&apos;\n&apos;for entry in $(cat /etc/passwd)do echo &quot;Value in $entry&quot; IFS=: for value in $entry do if [ -n &quot;$value&quot; ] then echo &quot;$value&quot; fi donedone 控制循环break命令可以用break退出任意的循环，包括while和until循环。也可以使用break -n跳出外部循环，默认为1。 continue命令continue命令可以提前终止某次循环中的命令，但并不会完全终止整个循环。也可以使用continue -n继续执行哪一层循环。 处理循环的输出可以对循环的输出使用管道或重定向。通过在done命令之后添加一个处理命令来实现。 done &gt; output.txt 例子创建多个用户账户 123456input=&quot;user.csv&quot;while IFS=&quot;,&quot; read -r userid namedo echo &quot;adding $userid&quot; useradd -c &quot;$name&quot; -m &quot;userid&quot; done &lt; &quot;$input&quot; 处理用户输入命令行参数向shell脚本传递数据的最基本方法是使用命令行参数。命令行参数允许在运行脚本时向命令行添加数据。 1./test.sh 10 abc bash shell会将一些位置参数的特殊变量分配给输入到命令行中的所有参数。这也包括shell所执行的脚本命令。其中：$0是程序名，$1是第一个参数，$2是第二个参数，一直到$9。 在使用时，需要用空格将每个命令行参数分隔开，例如: 1count=$[ $1 * $2 ] 注意，当命令行参数中出现空格时，需要使用引号： 1./test1.sh &apos;hello world&apos; 如果命令行参数的数量超过9个时，从第十个参数开始，需要使用花括号，例如${10}、${11}等。 使用basename命令可以返回不包含路径的脚本名，例如： 12echo &quot;$0&quot;echo &quot;$(basename $0)&quot; 在使用命令行参数的脚本中，需要先检测其中是否存在数据： 1if [ -n &quot;$1&quot; ] 特殊的参数变量特殊变量$#含有脚本运行时携带的命令行参数的个数，例如： 1echo There are $# parameters supplied. 使用$&#123;!#&#125;可以返回最后一个命令行参数的值，如果命令行参数的个数为0，则返回当前脚本的名称。 使用$*和$@可以访问所有的参数。其中$*变量会将命令行上提供的所有参数当作一个单词保存。这个单词包括了命令行中出现的每一个参数值；$@变量会将命令行上所有参数当作同一个字符串中的多个独立的单词，然后通过遍历获取所有的参数值。 12345678910111213count=1for param in &quot;$*&quot;do echo &quot;\$* parameter #count = $param&quot; count=$[ $count + 1 ]doneechocount=1for param in &quot;$@&quot;do echo &quot;\$@ parameter #count = $param&quot; count=$[ $count + 1 ]done 移动变量bash shell的shift命令可以用来操作命令行参数，shift命令会根据命令行参数的相对位置来移动。在默认情况下，会将每个参数变量向左移动一个位置。其中$2的值会移动到$1，而$1的值则会被删除，$0不会改变。 12345while [ -n &quot;$1&quot; ]do echo &quot;$1&quot; shiftdone 也可以一次性移动多个位置 shift n 处理选项选项是跟在单破折号后面的单个字母，可以用来改变命令的行为。可以使用--来表明选项列表结束。 getopt命令getopt命令能够识别命令行参数，从而在脚本中解析更加方便。 命令格式： getopt optstring parameters 其中optstring定义了命令行有效的选项字母，还定义了哪些选项字母需要参数值。 12getopt ab:cd -a -b test1 -cd test2 test3-a -b test1 -c -d -- test2 test3 如果指定了一个不再optstring中的选项，默认情况下，getopt命令会产生一条错误消息。可以在命令后加-q忽略。 在脚本中使用getopt set – $(getopt -q ab:cd “$@”) getopts命令命令格式如下： getopts optstring variable 如果选项需要跟一个参数值，OPTARG环境变量就会保存这个值。OPTIND环境变量保存了参数列表中getopts正在处理的参数位置。 获取用户输入使用read命令获取用户输入。 read命令从标准输入或另一个文件描述符接收输入。在收到输入后，read命令会将数据放进一个变量。 12read -p &quot;Enter your name: &quot; first lastecho $last, $first 如果在read命令行中不指定变量，那么read命令会将它收到的任何数据都放进特殊环境变量REPLY中： 12read -p &quot;Enter your name: &quot;echo $REPLY 在使用read命令时，需要注意超时时间，可以使用-t选项来指定计时器 1read -t 5 -p &quot;Please enter your name: &quot; name 如果需要隐藏输入的值时，可以使用-s选项。read在读取文件时，每次从文件中读取一行文本，当文件中没有内容时，read命令将会退出并返回非零退出状态码。 1cat test | while read line 呈现数据 文件描述符 缩写 描述 0 STDIN 标准输入 1 STDOUT 标准输出 2 STDERR 标准错误 默认情况下，STDERR文件描述符和STDOUT文件描述符指向同样的地方。 只重定向错误： ls -al errorfile 2&gt; test 重定向错误和数据： ls -al test.txt errorfile 2&gt;test 1&gt;test1 同时重定向STDERR和STDOUT： ls -al test.txt errorfile &amp;&gt;test2 如果需要重定向到某个文件描述符时，必须在文件描述符之前加一个&amp;： 1echo &quot;This is an error&quot; &gt;&amp;2 可以使用exec命令进行永久重定向： 12exec 1&gt; testoutexec 0&lt; testin 关闭文件描述符： 1exec 3&gt;&amp;- 如果需要阻止命令输出，可以将STDERR重定向到/dev/null。 也可以在/tmp目录中创建临时文件或文件夹。使用mktemp在本地目录创建临时文件。创建时，只需要指定一个临时模板： 123456#在当前目录创建临时文件，并返回文件名mktemp testing.xxxxxx#在系统临时目录创建临时文件，并返回全路径mktemp -t tmp.xxxxxx#在当前目录创建临时文件夹，并返回文件夹名mktemp -d dir.xxxxxx 使用tee命令可以将输出同时发送到显示器和日志文件中 date | tee testfile #将文件进行追加，使用-a选项 date | tee -a testfile 实例1234567891011#!/bin/bashoutputfile=&quot;person.sql&quot;IFS=&apos;,&apos;while read name age addressdo cat &gt;&gt; $outputfile &lt;&lt; EOF insert into person(name,age,address) values(&apos;$name&apos;,&apos;$age&apos;,&apos;$address&apos;); EOFdone &lt; $1 ./test.sh testfile 脚本控制处理信号常用的Linux信号如下： 信号 值 描述 1 SIGHUP 挂起进程 2 SIGINT 终止进程 3 SIGQUIT 停止进程 9 SIGKILL 无条件终止进程 15 SIGTERM 尽可能终止进程 17 SIGSTOP 无条件停止进程，但不是终止进程 18 SIGTSTP 停止或暂停进程，但不终止进程 19 SIGCONT 继续运行停止的进程 Ctrl+Z组合键会生成一个SIGTSTP信号，停止shell中运行的任何进程。停止进程会让程序继续保留在内存中，并能从上次停止的位置继续运行。 使用exit退出停止的作业，使用ps -l查看已停止的作业。 可以使用trap命令来捕获信号，其命令格式为： trap command signals 或者在trap命令后加上EXIT信号来捕获脚本的退出： 1trap &quot;echo end...&quot; EXIT 也可以重新使用带有选项的trap命令在脚本中的不同位置进行不同的捕获处理。 以后台模式运行脚本直接在命令后面添加&amp;即可： ./test.sh &amp; 注意：在ps命令的输出中，每一个后台进程都和终端会话终端联系在一起。如果终端会话退出，那么后台进程也会随之退出。 此时可以使用nohup命令来阻止后台进程在终端退出时也一起终止： nohup ./test.sh &amp; 作业控制作业控制：启动、停止终止以及恢复作业的功能。 使用jobs命令查看shell当前正在处理的作业。jobs命令参数如下： 参数 描述 -l 列出进程的PID以及作业号 -n 只列出上次shell发出的通知后改变了状态的作业 -p 只列出作业的PID -r 只列出运行中的作业 -s 只列出已停止的作业 如果要以后台模式重启一个作业，可以用bg命令加上作业号： bg 2 如果要以前台模式重启一个作业，可以用fg命令加上作业号： fg 2 调整优先级调度优先级：内核分配给进程的CPU时间。调度优先级是一个整数值，从-20(最高优先级)到+19(最低优先级)。默认情况下以优先级0来启动所有进程。 使用nice命令设置命令启动时的调度优先级，例如： nice -n 10 ./test.sh &gt; test.out &amp; 使用renice命令改变运行中进程的PID，例如： renice -n 10 -p 8888 定时运行作业使用at命令来计划执行作业。at命令会将作业提交到队列中，指定shell何时运行该作业。at命令的格式如下： at [-f filename] time 当作业在运行时，Linux系统会将提交该作业的用户的电子邮件地址作为STDOUT和STDERR。所以需要在脚本中对输出进行重定向。 使用atq命令查看系统中有哪些作业在等待。 使用atrm命令来删除等待中的作业。 使用cron程序Linux系统使用cron程序来安排要定期执行的作业。cron程序会在后台运行并检查一个特殊的表，以获知已安排执行的作业。 cron时间表的格式如下： min hour dayofmonth month dayof week command 如果想在每天下午15:20执行某个文件，可以设置为： 20 15 * * * * /home/zyj/shell/tesh.sh &gt; test.out 使用crontab命令来处理cron时间表。 函数基本函数创建函数 123function name &#123; commands&#125; 在函数中使用变量向函数传递参数在脚本中指定函数时，必须将参数和函数放在同一行，例如： func1 $value1 10 12345678910111213141516171819#!/bin/bashfunction add &#123; if [ $# -eq 0] || [ $# -gt 2] then echo -1 elif [ $# -eq 1 ] then echo $[ $1 + $1 ] else echo $[ $1 + $2 ] fi&#125;value1=$(add 10 15)value2=$(add 10)value3=$(add)value4=$(add 5 10 15)echo $value1 $value2 $value3 $value4 全局变量和局部变量使用local关键字定义局部变量。 local temp local关键字保证了变量只局限在该函数中。如果脚本中在该函数之外有同样名字的变量，那么shell将会保持这两个变量的值是分离的。 数组变量和函数向函数传递数组参数 12345678910#!/bin/bashfunction testArr &#123; local newArr newArr=(&quot;$@&quot;) echo &quot;The new array is $&#123;newArr[*]&#125;&quot;&#125;myArr=(1 2 3 4 5)testArr $&#123;myArr[*]&#125; 从函数返回数组 函数递归计算阶乘 12345678910111213141516#!/bin/bashfunction factorial &#123; if [ $1 -eq 1 ] then echo 1 else local temp=$[ $1 - 1 ] local result=$(factorial $temp) echo $[ $result * $1 ] fi&#125;read -p &quot;Enter a number:&quot; valueresult=$(factorial $value)echo &quot;The result is: &quot; $result]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux之grep详解]]></title>
    <url>%2F2018%2F02%2F03%2FLinux-grep%2F</url>
    <content type="text"><![CDATA[grep（global search regular expression(RE) and print out the line）是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹配的行打印出来。 选项 -a 不要忽略二进制数据。 -A&lt;显示列数&gt; 除了显示符合范本样式的那一行之外，并显示该行之后的内容。 -b 在显示符合范本样式的那一行之外，并显示该行之前的内容。 -c 计算符合范本样式的列数。 -C&lt;显示列数&gt;或-&lt;显示列数&gt; 除了显示符合范本样式的那一列之外，并显示该列之前后的内容。 -d&lt;进行动作&gt; 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep命令将回报信息并停止动作。 -e&lt;范本样式&gt; 指定字符串作为查找文件内容的范本样式。 -E 将范本样式为延伸的普通表示法来使用，意味着使用能使用扩展正则表达式。 -f&lt;范本文件&gt; 指定范本文件，其内容有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每一列的范本样式。 -F 将范本样式视为固定字符串的列表。 -G 将范本样式视为普通的表示法来使用。 -h 在显示符合范本样式的那一列之前，不标示该列所属的文件名称。 -H 在显示符合范本样式的那一列之前，标示该列的文件名称。 -i 忽略字符大小写的差别。 -l 列出文件内容符合指定的范本样式的文件名称。 -L 列出文件内容不符合指定的范本样式的文件名称。 -n 在显示符合范本样式的那一列之前，标示出该列的编号。 -q 不显示任何信息。 -R/-r 此参数的效果和指定“-d recurse”参数相同。 -s 不显示错误信息。 -v 反转查找。 -w 只显示全字符合的列。 -x 只显示全列符合的列。 -y 此参数效果跟“-i”相同。 -o 只输出文件中匹配到的部分。 常见用法在文件中搜索一个单词，命令会返回一个包含“match_pattern”的文本行： grep match_pattern file_name grep “match_pattern” file_name 在多个文件中查找： grep “match_pattern” file_1 file_2 file_3 … 输出除之外的所有行 -v 选项： grep -v “match_pattern” file_name 使用正则表达式 -E 选项： grep -E “[1-9]+” 或 egrep “[1-9]+” 只输出文件中匹配到的部分 -o 选项： echo this is a test line. | grep -o -E “[a-z]+.“ line. echo this is a test line. | egrep -o “[a-z]+.“ line. 统计文件或者文本中包含匹配字符串的行数 -c 选项： grep -c “text” file_name 输出包含匹配字符串的行数 -n 选项： grep “text” -n file_name 或 cat file_name | grep “text” -n #多个文件 grep “text” -n file_1 file_2 搜索多个文件并查找匹配文本在哪些文件中： grep -l “text” file1 file2 file3… 练习 获取root用户的shell程序 1cat /etc/passwd|grep ^root.*&quot;/root:&quot; | cut -d : -f 7 显示CentOS7的/etc/grub2.cfg文件中，至少以一个空白 字符开头的且后面存非空白字符的行 1cat /etc/grub2.cfg | egrep &quot;^[[:space:]] [^[:space:]]&quot; 找出netstat -tan命令的结果中以LISTEN后跟任意多个空白字符结尾的行 1netstat -tan | grep &quot;.*LISTEN.*$&quot;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的正则表达式]]></title>
    <url>%2F2018%2F02%2F03%2FLinux-regular%2F</url>
    <content type="text"><![CDATA[通配符 元字符 作用 * 匹配0个或任意多个字符，也就是可以匹配任何内容 ? 匹配任意一个字符 [] 匹配[ ]中任意一个字符 [-] 匹配括号中任意一个字符，-代表一个范围，例如：[a-z]代表匹配一个小写字母 [^] 逻辑非，表示匹配不是中括号内的一个字符，例如[^0-9]代表匹配一个不是数字的字符 正则表达式基础正则表达式 元字符 作用 * 前一个字符匹配0次或任意多次，匹配0次前一个字符则表示匹配任意字符，包括空白行 . 匹配除了换行符以外任意一个字符，“.*”匹配所有内容 ^ 用于指定匹配字符串的头部，也称行首定位符；匹配行首。例如：^hello会匹配以hello开头的行，grep -n “^$” test.txt匹配空白行并显示行号 $ 用于指定匹配字符串的尾部，也称行尾定位符；匹配行尾。例如：hello$会匹配以hello结尾的行 [] 匹配中括号中指定的任意一个字符，只匹配一个字符，要匹配[则要转义[ [^] 匹配除中括号的字符以外的任意一个字符 \ 转义符用于取消特殊符号的含义，匹配包含以.结尾的行grep “.$” test.txt {n} 表示其前面的字符恰好出现n次。例如：[0-9]{4}匹配4位数字，但注意添加两边的定界符，以精确匹配 {n,} 表示其前面的字符出现不小于n次。例如：[0-9]{2,}匹配2位以上的数字 {n,m} 表示其前面的字符至少出现n次，最多出现m次。例如：[a-z]{6,8}匹配6到8位的小写字母 注1：?、()是扩展正则中的元字符 注2：正则表达式中使用以上的元字符，如[]、{}、*、.等所以在匹配字符串中包含有这些元字符时必须使用反斜杠\\转义，但像&lt;&gt;这个非元字符符号就不需要转义。 特殊字符正则表达式识别的特殊字符包括： .*[]^$&#123;&#125;\+?() 如果需要将特殊字符当作普通字符来使用，必须对特殊字符进行转义。 特殊字符组 组 描述 [[:alpha:]] 匹配任意的字母字符，不管是大写还是小写 [[:alnum:]] 匹配任意的字母数字字符0~9，A~Z或a~z [[:blank:]] 匹配空格或制表符 [[:digit:]] 匹配0~9之间的数字 [[:lower:]] 匹配小写字母字符a~z [[:print:]] 匹配任意可打印字符 [[:punct:]] 匹配标点符号 [[:space:]] 匹配任意空白字符：空格、制表符、NF、FF、VT和CR [[:upper:]] 匹配任意大写字母字符A~Z 扩展正则表达式 需要注意的是，gawk程序可以识别扩展正则表达式，而sed编辑器不能。 元字符 作用 &#124; 管道符，表示或，即匹配其中任何一个，book&#124;desk将匹配book或desk () 小括号，可以将正则字符和元字符或表达式进行组合，(book&#124;desk)s将匹配books或desks ? 问号，匹配0个或1个前导表达式，如a?匹配其他字符串或a \&lt; 反斜杠+小于号，词首定位符， \&lt; abc表示所有包含以abc开头的单词的行 \&gt; 反斜杠+大于号，词尾定位符， \&gt;abc表示所有包含以abc结尾的单词的行 - 减号，用于指明字符范围， [a-c]将匹配包含a、b和c中任意一个字符的字符串 + 加号，匹配一个或多个前导表达式，相当于expr{1,} &#123;&#125; 为重复的正则表达式设定一个范围 练习目录文件计数123456789101112131415#!/bin/bashmypath=$(echo $PATH | sed &apos;s/:/ /g&apos;)count=0for dir in $mypathdo subdir=$(ls $dir) for item in $subdir do count=$[ $count + 1] done echo &quot;$dir ---- $count&quot; count=0done 解析邮件地址1^([a-zA-Z0-9_\-\.\+]+)@([a-zA-Z0-9_\-\.]+)\.([a-zA-Z]&#123;2,5&#125;)$]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux之awk详解]]></title>
    <url>%2F2018%2F02%2F03%2FLinux-awk%2F</url>
    <content type="text"><![CDATA[awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。在awk中可以定义变量来保存数据，使用算术和字符串操作符来处理数据，使用结构化编程概念来为数据处理增加处理逻辑，以及提取文件的数据并做处理生成报告。awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk是AWK的GNU版本。 命令格式 awk ‘{pattern + action}’ {filenames} 其中pattern表示AWK在数据中查找的内容，而action是在找到匹配内容时所执行的一系列命令。花括号({})不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。pattern就是要表示的正则表达式，用斜杠括起来。 调用方式awk的调用方式通常分为以下三种： 命令行方式 awk [-F field-separator] ‘commands’ input-file(s) 其中，commands 是真正awk命令，[-F域分隔符]是可选的。 input-file(s) 是待处理的文件。在awk中，文件的每一行中，由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。 shell脚本方式将所有的awk命令插入一个文件，并使awk程序可执行，然后awk命令解释器作为脚本的首行，一遍通过键入脚本名称来调用。 相当于shell脚本首行的：#!/bin/sh 可以换成：#!/bin/awk 将所有的awk命令插入一个单独文件，然后调用 awk -f awk-script-file input-file(s) 其中，-f选项加载awk-script-file中的awk脚本，input-file(s)跟上面的是一样的。 入门实例 显示最近登录的5个账号名 1last -n 5 | awk &apos;&#123;print $1&#125;&apos; awk工作流程是这样的：读入有’\n’换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域。默认域分隔符是”空白键” 或 “[tab]键”,所以$1表示登录用户，$3表示登录用户ip,以此类推。 只显示/etc/passwd的账户名 1cat /etc/passwd | awk -F&apos;:&apos; &apos;&#123;print $1&#125;&apos; 这种是awk+action的示例，每行都会执行action{print $1}。 -F指定域分隔符为:。 只显示/etc/passwd的账户和账户对应的shell,并且账户与shell之间以tab键分割 1cat /etc/passwd | awk -F&apos;:&apos; &apos;&#123;print $1&quot;\t&quot;$7&#125;&apos; 只显示/etc/passwd的账户和账户对应的shell,账户与shell之间以逗号分割,并且在所有行前添加列名name,shell,在最后一行添加”blue,/bin/nosh”。 1cat /etc/passwd | awk -F&apos;:&apos; &apos;BEGIN&#123;print &quot;name,shell&quot;&#125; &#123;print $1&quot;,&quot;$7&#125; END&#123;print &quot;blue,/bin/nosh&quot;&#125;&apos; awk工作流程是这样的：先执行BEGIN，然后读取文件，读入有/n换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域,随后开始执行模式所对应的动作action。接着开始读入第二条记录······直到所有的记录都读完，最后执行END操作。 搜索/etc/passwd有root关键字的所有行 1cat /etc/passwd | awk -F&apos;:&apos; &apos;/root/&apos; 这种是pattern的使用示例，匹配了pattern(这里是root)的行才会执行action(没有指定action，默认输出每行的内容)。 搜索支持正则，例如找root开头的: awk -F: &#39;/^root/&#39; /etc/passwd 获取/etc/passwd有root关键字的所有行，并显示对应的shell 1cat /etc/passwd | awk -F: &apos;/root/&#123;print $7&#125;&apos; awk内置变量awk有许多内置变量用来设置环境信息，这些变量可以被改变，下面给出了最常用的一些变量。 变量名 说明 ARGC 命令行参数个数 ARGV 命令行参数排列 ENVIRON 支持队列中系统环境变量的使用 FILENAME awk浏览的文件名 FNR 浏览文件的记录数 FS 设置输入域分隔符，等价于命令行 -F选项 NF 浏览记录的域的个数 NR 已读的记录数 OFS 输出域分隔符 ORS 输出记录分隔符 RS 控制记录分隔符 练习 统计/etc/passwd:文件名，每行的行号，每行的列数，对应的完整行内容 1awk -F&apos;:&apos; &apos;&#123;print &quot;filename: &quot; FILENAME &quot;, linenumber: &quot; NR &quot;, columns: &quot; NF &quot;, linecontent: &quot; $0&#125;&apos; /etc/passwd print和printfawk中同时提供了print和printf两种打印输出的函数。其中print函数的参数可以是变量、数值或者字符串。字符串必须用双引号引用，参数用逗号分隔。如果没有逗号，参数就串联在一起而无法区分。这里，逗号的作用与输出文件的分隔符的作用是一样的，只是后者是空格而已。printf函数，其用法和c语言中printf基本相似,可以格式化字符串,输出复杂时，printf更加好用，代码更易懂。 可以将上面的例子1改写为以下形式： 12 awk -F&apos;:&apos; &apos;&#123;printf(&quot;filename: %10s, linenumber: %s, columns: %s, linecontent: %s\n&quot;, FILENAME, NR, NF, $0)&#125;&apos; /etc/passwd awk编程变量和赋值除了awk的内置变量，awk还可以自定义变量。 统计/etc/passwd的账户人数 1awk &apos;BEGIN&#123;count=0&#125; &#123;count++&#125; END&#123;print &quot;the number of users is &quot;,count&#125;&apos; /etc/passwd 统计某个文件夹下的文件占用的字节数 1ls -l | awk &apos;BEGIN&#123;size=0&#125; &#123;size+=$5;&#125; END&#123;print &quot;[end]size is &quot;,size&#125;&apos; 条件语句awk中的条件语句是从C语言中借鉴来的，声明方式如下： if (expression) { statement; statement; … … } 或 if (expression) { statement; } else { statement2; } 或 if (expression) { statement1; } else if (expression1) { statement2; } else { statement3; } 统计某个文件夹下的文件占用的字节数,过滤4096大小的文件 1ls -l | awk &apos;BEGIN&#123;size=0&#125; &#123;if($5==4096)&#123;size+=$5&#125;&#125; END&#123;print &quot;the size of file is &quot;,size&#125;&apos; 循环语句awk中的循环语句同样借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。 数组因为awk中数组的下标可以是数字和字母，数组的下标通常被称为关键字(key)。值和关键字都存储在内部的一张针对key/value应用hash的表格里。由于hash不是顺序存储，因此在显示数组内容时会发现，它们并不是按照你预料的顺序显示出来的。数组和变量一样，都是在使用时自动创建的，awk也同样会自动判断其存储的是数字还是字符串。一般而言，awk中的数组用来从记录中收集信息，可以用于计算总和、统计单词以及跟踪模板被匹配的次数等等。 显示/etc/passwd的账户 1awk -F&apos;:&apos; &apos;BEGIN&#123;count=0;&#125; &#123;name[count]=$1;count++&#125; END&#123;for(i=0;i&lt;NR;i++)&#123;print i, name[i]&#125;&#125;&apos; /etc/passwd 练习 取出/etc/passwd中的账户名以a或b开头的行并排序 1awk &apos;$1~/^(a|b)/&#123;print $0&#125;&apos; /etc/passwd | sort 这里需要注意~是进行对$1的模糊匹配的意思。 取出常用服务及其端口号 1cat /etc/services | awk -F&apos;[ /]+&apos; &apos;$1~/^(ssh|ftp|https)/&#123;print $1,$2&#125;&apos;| uniq 获取文件中空行的数量 123awk &apos;BEGIN&#123;count=0&#125; &#123;if($0==&quot;&quot;)&#123;count++&#125;&#125; END&#123;print count&#125;&apos; filename或awk &apos;BEGIN&#123;count=0&#125; /^$/&#123;count++&#125; END&#123;print count&#125;&apos; filename 从链接中获取域名 1awk -F&apos;/&apos; &apos;&#123;array[$3]++&#125;END&#123;for(key in array)&#123;print key,array[key]&#125;&#125;&apos; filename]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux之sed详解]]></title>
    <url>%2F2018%2F02%2F03%2FLinux-sed%2F</url>
    <content type="text"><![CDATA[sed是一种流编辑器，它是文本处理中常营的工具，能够完美的配合正则表达式使用。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。 命令格式sed [-nefri] ‘command’ 输入文本 常用选项-n∶使用安静(silent)模式。在一般 sed 的用法中，所有来自STDIN的资料一般都会被列出到屏幕上。但如果加上-n参数后，则只有经过sed特殊处理的那一行(或者动作)才会被列出来。-e∶直接在指令列模式上进行sed的动作编辑；或者需要在sed命令行上执行多个命令；例如sed -e &#39;s/brown/green/; s/dog/cat/&#39; test.txt；-f∶直接将sed的动作写在一个档案内，-f filename则可以执行 filename 内的sed 动作；-r∶sed的动作支援的是延伸型正规表示法的语法。(预设是基础正规表示法语法)-i∶直接修改读取的档案内容，而不是由屏幕输出。 常用命令a：新增，a的后面可以接字串，而这些字串会在新的一行出现(目前的下一行)c：取代，c的后面可以接字串，这些字串可以取代n1,n2之间的行d：删除，由于是删除，所以d后面通常不接任何符号g：新文本将会替换所有匹配的文本i：插入，i的后面可以接字串，而这些字串会在新的一行出现(目前的上一行)l：打印数据流中的文本和不可打印的ASCII字符p：打印，即将某个匹配的字符串打印。通常p会与参数 sed -n 一起使用r：将一个独立文件中的数据插入到数据流中s：替换，直接将匹配的字符串进行替换。通常与正则表达式一起使用w file：将替换的结果写到文件中 使用文本过滤器格式如下： /pattern/command 1sed &apos;/jimmy/s/bash/csh/&apos; /etc/passwd sed进阶多行命令N：将数据流中的下一行加进来创建一个多行组来处理；D：删除多行组中的一行；注意：D命令会强制sed编辑器返回到脚本的顶部，而不读取新的行；P：打印多行组中的一行。 next命令 123sed &apos;/head/&#123;n ; d&#125;&apos; data.txt #删除含有head行的下一行sed &apos;/first/&#123;N ; s/\n/ /&#125;&apos; data.txt #将含有first的行以及下一行当作一行处理sed &apos;N ; s/System.Administrator/Desktop User&apos; data.txt 多行删除 1sed &apos;/^$/&#123;N ; /header/D&#125;&apos; data.txt #首先找到空白行，然后将下一行合并到模式空间内，由于D只会删除模式空间里的第一行，所以只会删除含有header行前的空白行 多行打印 1sed -n &apos;N ; /System\nAdministrator/P&apos; data.txt #只打印多行模式空间中的第一行 保持空间模式空间是一块活跃的缓冲区，在sed编辑器执行命令时它会保存待检查的文本。但它并不是sed编辑器保存文本的唯一空间。 sed编辑器有另一块称作保持空间的缓冲区域。在处理模式空间中的某些行时，可以用保持空间来临时保存一些行。 sed编辑器的保持空间命令： 命令 描述 h 将模式空间复制到保持空间 H 将模式空间附加到保持空间 g 将保持空间复制到模式空间 G 将保持空间附加到模式空间 x 交换模式空间和保持空间的内容 1sed -n &apos;/first/&#123;h ; n ; p; g; p&#125;&apos; data.txt #将含有first的行和后面一行交换顺序输出 排除命令使用感叹号(!)来排除命令，即让原本会起作用的命令不起作用。 1sed -n &apos;&#123;1!G ; h ; $p&#125;&apos; data.txt 改变流分支命令b，格式如下：[address]b [label] 1sed &apos;&#123;2,3b; s/This is/Is this/; s/line./test?/&#125;&apos; data.txt #在第2、3行跳过替换 测试命令t，根据替换命令的结果跳转到某个标签，而不是根据地址进行跳转，格式如下：[address]t [label] 模式替代使用&amp;符号用来代表替换命令中的匹配的模式 1$ echo &quot;The cat sleeps in his hat.&quot; | sed &apos;s/.at/&quot;&amp;&quot;/g&apos; sed使用圆括号来定义替换模式中的子模式。 12$ echo &quot;The System Administrator manual&quot; | sed &apos;s/\(System\) Administrator/\1 User/g&apos; 实例删除行12345sed &apos;1d&apos; filename #删除第一行 sed &apos;$d&apos; filename #删除最后一行sed &apos;1,2d&apos; filename #删除第一行到第二行sed &apos;2,$d&apos; filename #删除第二行到最后一行sed &apos;/1/,/3/d&apos; filename #在遇到数据行中有1时开始删除，遇到有3的行停止删除 显示行1234sed -n &apos;1p&apos; filename #显示第一行 sed -n &apos;$p&apos; filename #显示最后一行sed -n &apos;1,2p&apos; filename #显示第一行到第二行sed -n &apos;2,$p&apos; filename #显示第二行到最后一行 查询12sed -n &apos;/centos/p&apos; filename #查询包括关键字centos所在所有行sed -n &apos;/\$/p&apos; filename #查询包括关键字$所在所有行，使用反斜线\对特殊字符进行转义 增加一行或多行字符串123sed &apos;1a drink tea&apos; filename #第一行后增加字符串&quot;drink tea&quot;sed &apos;1,3a drink tea&apos; filename #第一行到第三行后增加字符串&quot;drink tea&quot;sed &apos;1a drink\ncoffee&apos; filename #第一行后增加多行，使用换行符\n 替换一行或多行12sed &apos;1c Hi&apos; filename #第一行代替为Hised &apos;1,2c Hi&apos; filename #第一行到第二行代替为Hi 替换一行中的某部分 格式 sed ‘s/要替换的字符串/新的字符串/g’ (要替换的字符串可以用正则表达式) 123sed -n &apos;/centos/p&apos; filename | sed &apos;s/centos/redhat/g&apos; #替换centos为redhatsed -n &apos;/centos/p&apos; filename | sed &apos;s/centos//g&apos; #删除centossed &apos;s/test/trial/2&apos; data.txt #只替换每行第二次出现的test 插入12sed -i &apos;$a bye&apos; filename #在文件filenamede 最后一行直接输入&quot;bye&quot;sed -n &apos;2,$p&apos; filename #显示第二行到最后一行 转换1sed &apos;y/123/789/&apos; test.txt 将1替换为7,2替换为8,3替换为9 习题 从ip addr中找到当前主机的ip 12ip addr|sed -nr &apos;s/.*inet (.*)\/24.*$/\1/gp&apos;192.168.17.131 将/etc/passwd第一项和最后一项互换 1cat /etc/passwd | sed -nr &apos;s/(.*)(:x.*:)(.*$)/\3\2\1/gp&apos; 加倍行间距 123$ sed &apos;$!G&apos; data.txt#如果文本中本身就有空白行$ sed &apos;/^$/d; $!G&apos; data.txt 给文件中的行编号 1$ sed &quot;=&quot; data.txt | sed &apos;N; s/\n/ /g&apos; 打印文件末尾的若干行 12345$ sed &apos;&#123; :start $q; N ; 11,$D b start &#125;&apos; data.txt 删除连续的空白行 1$ sed &apos;/./,/^$/!d&apos; data.txt 删除开头的空白行 1$ sed &apos;/./,$!d&apos; data.txt 删除结尾的空白行 1234$ sed &apos;&#123; :start /^\n*$/&#123;$d ; N ; b start&#125; &#125;&apos; data.txt 删除HTML标签 1$ sed &apos;s/&lt;[^&gt;]*&gt;//g ; /^$/d&apos; data.txt]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常用命令]]></title>
    <url>%2F2018%2F02%2F01%2FLinux-commands%2F</url>
    <content type="text"><![CDATA[系统信息显示机器的处理器架构 arch uname -m 显示正在使用的内核版本 uname -r 显示CPU的信息 cat /proc/cpuinfo 显示内存使用 cat /proc/meminfo 显示内核的版本 cat /proc/version 显示系统日期 date 同步时间 ntpdate time.ntp.org 关机关闭系统 shutdown -h now init 0 重启 shutdown -r now reboot 注销 logout 文件和目录cd /home 进入/home目录 .. 返回上一级目录 - 返回上次所在的目录 pwd显示工作路径 ls -F 查看目录中的文件 -l 显示文件和目录的详细资料 -a 显示隐藏文件 mkdir创建目录 -Z：设置安全上下文，当使用SELinux时有效； -m&lt;目标属性&gt;或–mode&lt;目标属性&gt;建立目录的同时设置目录的权限； -p或–parents 若所要建立目录的上层目录目前尚未建立，则会一并建立上层目录； –version 显示版本信息。 rm rm -f file1 删除一个叫做 ‘file1’ 的文件’ rm dir dir1 删除一个叫做 ‘dir1’ 的目录’ rm -rf dir1 删除一个叫做 ‘dir1’ 的目录并同时删除其内容 rm -rf dir1 dir2 同时删除两个目录及它们的内容 mv mv dir1 new_dir 重命名/移动 一个目录 cp cp file1 file2 复制一个文件 cp dir/* . 复制一个目录下的所有文件到当前工作目录 cp -a /tmp/dir1 . 复制一个目录到当前工作目录 cp -a dir1 dir2 复制一个目录 ln文件搜索find find / -name file1 从 ‘/‘ 开始进入根文件系统搜索文件和目录 find / -user user1 搜索属于用户 ‘user1’ 的文件和目录 find /home/user1 -name *.bin 在目录 ‘/ home/user1’ 中搜索带有’.bin’ 结尾的文件 find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件 find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件 find / -name *.rpm -exec chmod 755 ‘{}’ \; 搜索以 ‘.rpm’ 结尾的文件并定义其权限 find / -xdev -name *.rpm 搜索以 ‘.rpm’ 结尾的文件，忽略光驱、捷盘等可移动设备 locate locate *.ps 寻找以 ‘.ps’ 结尾的文件 - 先运行 ‘updatedb’ 命令 whereis whereis halt 显示一个二进制文件、源码或man的位置 which which halt 显示一个二进制文件或可执行文件的完整路径 挂载文件系统mountunmount磁盘空间df -a或–all：包含全部的文件系统； –block-size=&lt;区块大小&gt;：以指定的区块大小来显示区块数目； -h或–human-readable：以可读性较高的方式来显示信息； -H或–si：与-h参数相同，但在计算时是以1000 Bytes为换算单位而非1024 Bytes； -i或–inodes：显示inode的信息； -k或–kilobytes：指定区块大小为1024字节； -l或–local：仅显示本地端的文件系统； -m或–megabytes：指定区块大小为1048576字节； –no-sync：在取得磁盘使用信息前，不要执行sync指令，此为预设值； -P或–portability：使用POSIX的输出格式； –sync：在取得磁盘使用信息前，先执行sync指令； -t&lt;文件系统类型&gt;或–type=&lt;文件系统类型&gt;：仅显示指定文件系统类型的磁盘信息； -T或–print-type：显示文件系统的类型； -x&lt;文件系统类型&gt;或–exclude-type=&lt;文件系统类型&gt;：不要显示指定文件系统类型的磁盘信息； –help：显示帮助； –version：显示版本信息。 du -a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 -c或–total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或–kilobytes 以KB(1024bytes)为单位输出。 -m或–megabytes 以MB为单位输出。 -s或–summarize 仅显示总计，只列出最后加总的值。 -h或–human-readable 以K，M，G为单位，提高信息的可读性。 -x或–one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 -L&lt;符号链接&gt;或–dereference&lt;符号链接&gt; 显示选项中所指定符号链接的源文件大小。 -S或–separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -X&lt;文件&gt;或–exclude-from=&lt;文件&gt; 在&lt;文件&gt;指定目录或文件。 –exclude=&lt;目录或文件&gt; 略过指定的目录或文件。 -D或–dereference-args 显示指定符号链接的源文件大小。 -H或–si 与-h参数相同，但是K，M，G是以1000为换算单位。 -l或–count-links 重复计算硬件链接的文件。 用户和组useradd创建的新的系统用户。使用useradd指令所建立的帐号，实际上是保存在/etc/passwd文本文件中。 -c&lt;备注&gt;：加上备注文字。备注文字会保存在passwd的备注栏位中； -d&lt;登入目录&gt;：指定用户登入时的启始目录； -D：变更预设值； -e&lt;有效期限&gt;：指定帐号的有效期限； -f&lt;缓冲天数&gt;：指定在密码过期后多少天即关闭该帐号； -g&lt;群组&gt;：指定用户所属的群组； -G&lt;群组&gt;：指定用户所属的附加群组； -m：自动建立用户的登入目录； -M：不要自动建立用户的登入目录； -n：取消建立以用户名称为名的群组； -r：建立系统帐号； -s：指定用户登入后所使用的shell； -u：指定用户id。 userdel删除给定的用户，以及与用户相关的文件。若不加选项，则仅删除用户帐号，而不删除相关文件。 -f：强制删除用户，即使用户当前已登录； -r：删除用户的同时，删除与用户相关的所有文件。 passwd设置用户的认证信息，包括用户密码、密码过期时间等。系统管理者则能用它管理系统用户的密码。只有管理者可以指定用户名称，一般用户只能变更自己的密码。 -d：删除密码，仅有系统管理者才能使用； -f：强制执行； -k：设置只有在密码过期失效后，方能更新； -l：锁住密码； -s：列出密码的相关信息，仅有系统管理者才能使用； -u：解开已上锁的帐号。 groupadd创建一个新的工作组，新工作组的信息将被添加到系统文件中。 -g：指定新建工作组的id； -r：创建系统工作组，系统工作组的组ID小于500； -K：覆盖配置文件“/ect/login.defs”； -o：允许添加组ID号不唯一的工作组。 groupdel删除指定的工作组，本命令要修改的系统文件包括/ect/group和/ect/gshadow。若该群组中仍包括某些用户，则必须先删除这些用户后，方能删除群组。 文件权限chmod用来变更文件或目录的权限。在UNIX系统家族里，文件或目录权限的控制分别以读取、写入、执行3种一般权限来区分，另有3种特殊权限可供运用。用户可以使用chmod指令去变更文件与目录的权限，设置方式采用文字或数字代号皆可。符号连接的权限无法变更，如果用户对符号连接修改权限，其改变会作用在被连接的原始文件。 权限范围表示法如下：u User，即文件或目录的拥有者；g Group，即文件或目录的所属群组；o Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围；a All，即全部的用户，包含拥有者，所属群组以及其他用户；r 读取权限，数字代号为“4”;w 写入权限，数字代号为“2”；x 执行或切换权限，数字代号为“1”；- 不具任何权限，数字代号为“0”；s 特殊功能说明：变更文件或目录的权限。 -c或——changes：效果类似“-v”参数，但仅回报更改的部分； -f或–quiet或——silent：不显示错误信息； -R或——recursive：递归处理，将指令目录下的所有文件及子目录一并处理； -v或——verbose：显示指令执行过程； –reference=&lt;参考文件或目录&gt;：把指定文件或目录的所属群组全部设成和参考文件或目录的所属群组相同； &lt;权限范围&gt;+&lt;权限设置&gt;：开启权限范围的文件或目录的该选项权限设置； &lt;权限范围&gt;-&lt;权限设置&gt;：关闭权限范围的文件或目录的该选项权限设置； &lt;权限范围&gt;=&lt;权限设置&gt;：指定权限范围的文件或目录的该选项权限设置； chownchgrp打包和压缩gziptarzipyum软件包管理 yum install package_name 下载并安装一个rpm包 yum localinstall package_name.rpm 将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系 yum update package_name.rpm 更新当前系统中所有安装的rpm包 yum update package_name 更新一个rpm包 yum remove package_name 删除一个rpm包 yum list 列出当前系统中安装的所有包 yum search package_name 在rpm仓库中搜寻软件包 yum clean packages 清理rpm缓存删除下载的包 yum clean headers 删除所有头文件 yum clean all 删除所有缓存的包和头文件]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker的安装和使用]]></title>
    <url>%2F2018%2F02%2F01%2Fdocker%2F</url>
    <content type="text"><![CDATA[docker安装在最小化安装的情况下，docker是没有安装的，所以不需要先卸载。 安装yum-config-manager工具 1yum -y install yum-utils 设置Docker仓库 1yum-config-manager --add-repo https://docs.docker.com/v1.13/engine/installation/linux/repo_files/centos/docker.repo 更新yum源并安装最新的docker 12yum makecache fastyum -y install docker-engine 启动docker 12systemctl start dockersystemctl enable docker 升级docker 123yum makecache fastyum list docker-engine.x86_64 --showduplicates |sort -ryum -y install docker-engine-&lt;VERSION_STRING&gt;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim基础]]></title>
    <url>%2F2018%2F02%2F01%2Fvim_base%2F</url>
    <content type="text"><![CDATA[vim编辑器在内存缓冲区中处理数据。 vim编辑器有两种操作模式：普通模式和插入模式。 vim移动光标的命令：h-左 j-下 k-上 l-右 快速移动命令：PageDown、PageUp、G(最后一行)、num G(移动到第num行)、gg(移动到第一行) 编辑数据x 删除当前光标所在位置的字符dd 删除当前光标所在行dw 删除当前光标所在位置的单词d$ 删除当前光标所在位置至行尾的内容J 删除当前光标所在行尾的换行符u 撤销前一编辑命令a 在当前光标后追加数据 复制和粘贴先使用dd删除，然后使用p粘贴yw 复制一个单词y$ 复制到行尾 查找和替换/content n:s/old/new/ 替换:s/old/new/g:n,ms/old/new/g 替换行号n和m之间所有old:%s/old/new/g 替换整个文件中所有old:%s/old/new/gc 替换整个文件中的所有old，但在每次出现时提示]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper的安装和使用]]></title>
    <url>%2F2018%2F02%2F01%2Fzookeeper_install%2F</url>
    <content type="text"><![CDATA[jdk1.8的安装 由于采用最小化安装，所以centOS中并没有预安装的jdk，故不需要先卸载 12345rpm -qa|grep javamkdir /usr/java/mv jdk-8u161-linux-x64.tar.gz /usr/java/tar zxvf jdk-8u161-linux-x64.tar.gzmv jdk1.8.0_161/ jdk1.8 编辑配置文件，配置环境变量 12345678vim /etc/profileJAVA_HOME=/usr/java/jdk1.8CLASSPATH=$JAVA_HOME/lib/PATH=$PATH:$JAVA_HOME/binexport PATH JAVA_HOME CLASSPATHsource /etc/profile zookeeper安装123456mkdir /usr/zookeeper/mv zookeeper-3.4.11.tar.gz /usr/zookeeper/tar zxvf zookeeper-3.4.11.tar.gzcd zookeeper-3.4.11cd confcp zoo_sample.cfg zoo.cfg 新增zookeeper用户以及zookeeper组 12groupadd zookeeperuseradd -g zookeeper zookeeper 修改文件夹用户和组 12chown -R zookeeper zookeeper-3.4.11chgrp -R zookeeper zookeeper-3.4.11 新增data和logs文件夹 123cd /usr/zookeeper/zookeeper-3.4.11mkdir datamkdir logs 修改/usr/zookeeper/zookeeper-3.4.11/conf目录下的zoo.cfg文件 1234567891011121314151617181920212223242526272829303132333435363738# The number of milliseconds of each tick# zookeeper 定义的基准时间间隔，单位：毫秒tickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just# example sakes.# dataDir=/tmp/zookeeper # 数据文件夹dataDir=/usr/zookeeper/zookeeper-3.4.11/data # 日志文件夹dataLogDir=/usr/zookeeper/zookeeper-3.4.11/logs # the port at which the clients will connect# 客户端访问 zookeeper 的端口号clientPort=2181 # the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the# administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1 修改系统配置文件，添加环境变量 123456789vim /etc/profileJAVA_HOME=/usr/java/jdk1.8ZOOKEEPER_HOME=/usr/zookeeper/zookeeper-3.4.11CLASSPATH=$JAVA_HOME/lib/PATH=$PATH:$JAVA_HOME/bin:$ZOOKEEPER_HOME/binexport PATH JAVA_HOME CLASSPATHsource /etc/profile zookeeper常用命令1234zkServer.sh startzkServer.sh stopzkServer.sh statuszkServer.sh restart 以集群方式启动zookeeper 先备份配置文件，然后将配置文件中的注释行去除 12mv zoo.cfg zoo.cfg.standalonegrep -v &quot;^$&quot; zoo.cfg.standalone | grep -v &quot;^#&quot; &gt; zoo.cfg 修改配置文件，如下 123456789tickTime=2000initLimit=10syncLimit=5dataDir=/usr/zookeeper/zookeeper-3.4.11/datadataLogDir=/usr/zookeeper/zookeeper-3.4.11/logsclientPort=2181server.1=192.168.17.133:2888:3888server.2=192.168.17.134:2888:3888server.3=192.168.17.135:2888:3888 然后在配置的datadir目录下，创建一个名为myid的文件，在该文件的第一行写上一个数字，与配置文件中server.后的数字一直 123echo 1 &gt; data/myidecho 2 &gt; data/myidecho 3 &gt; data/myid 在启动zookeeper集群前，需要先关闭防火墙 123systemctl stop firewalld.servicesystemctl disable firewalld.servicefirewall-cmd --state zookeeper的可执行脚本 脚本 说明 zkCleanup 清理Zookeeper的历史数据，包括事务日志和快照数据文件 zkCli ZooKeeper的一个建议客户端 zkEvn 设置ZooKeeper的环境变量 zkServer ZooKeeper服务器的启动、停止和重启脚本]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx中proxy_pass和rewrite详解]]></title>
    <url>%2F2018%2F01%2F31%2Fnginx_proxypass_rewrite%2F</url>
    <content type="text"><![CDATA[proxy_pass和rewriteproxy_pass123Syntax: proxy_pass URL;Default: —Context: location, if in location, limit_except 不影响浏览器地址栏的url 设置被代理server的协议和地址，URI可选(可以有，也可以没有) 协议可以为http或https 地址可以为域名或者IP，端口可选；eg： 1proxy_pass http://localhost:8000/uri/; 如果一个域名可以解析到多个地址，那么这些地址会被轮流使用，此外，还可以把一个地址指定为 server group（如：nginx的upstream）, eg: 1234567891011121314upstream backend &#123; server backend1.example.com weight=5; server backend2.example.com:8080; server unix:/tmp/backend3; server backup1.example.com:8080 backup; server backup2.example.com:8080 backup;&#125; server &#123; location / &#123; proxy_pass http://backend; &#125;&#125; server name，port， URI支持变量的形式，eg： 1proxy_pass http://$host$uri; 这种情况下，nginx会在server groups（upstream后端server）里搜索server name，如果没有找到，会用dns解析请求的URI按照下面的规则传给后端server 6.1. 如果proxy_pass的URL定向里包括URI，那么请求中匹配到location中URI的部分会被proxy_pass后面URL中的URI替换，eg： 1234location /name/ &#123; proxy_pass http://127.0.0.1/remote/;&#125;# 请求http://127.0.0.1/name/test.html 会被代理到http://127.0.0.1/remote/test.html 6.2. 如果proxy_pass的URL定向里不包括URI，那么请求中的URI会保持原样传送给后端server，eg： 1234location /name/ &#123; proxy_pass http://127.0.0.1;&#125;#请求http://127.0.0.1/name/test.html 会被代理到http://127.0.0.1/name/test.html 6.3. 一些情况下，不能确定替换的URI： location里是正则表达式，这种情况下，proxy_pass里最好不要有URI； 在proxy_pass前面用了rewrite，如下，这种情况下，proxy_pass是无效的，eg:1234location /name/ &#123; rewrite /name/([^/]+) /users?name=$1 break; proxy_pass http://127.0.0.1;&#125; rewrite123syntax: rewrite regex replacement [flag]Default: —Context: server, location, if 如果正则表达式（regex）匹配到了请求的URI（request URI），这个URI会被后面的replacement替换 rewrite的定向会根据他们在配置文件中出现的顺序依次执行 通过使用flag可以终止定向后进一步的处理 如果replacement以“http://”, “https://”, or “$scheme”开头，处理将会终止，请求结果会以重定向的形式返回给客户端（client） 如果replacement字符串里有新的request参数，那么之前的参数会附加到其后面，如果要避免这种情况，那就在replacement字符串后面加上“？”，eg： 1rewrite ^/users/(.*)$ /show?user=$1? last;= 如果正则表达式（regex）里包含“}” or “;”字符，需要用单引号或者双引号把正则表达式引起来 可选的flag参数如下： last 结束当前的请求处理，用替换后的URI重新匹配location； 可理解为重写（rewrite）后，发起了一个新请求，进入server模块，匹配location； 如果重新匹配循环的次数超过10次，nginx会返回500错误； 返回302 http状态码 ； 浏览器地址栏显示重地向后的url break 结束当前的请求处理，使用当前资源，不在执行location里余下的语句； 返回302 http状态码 ； 浏览器地址栏显示重定向后的url redirect 临时跳转，返回302 http状态码； 浏览器地址栏显示重定向后的url permanent 永久跳转，返回301 http状态码； 浏览器地址栏显示重定向后的url]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx+Keepalived的安装和使用]]></title>
    <url>%2F2018%2F01%2F31%2Fkeepalived_nginx%2F</url>
    <content type="text"><![CDATA[vim安装1yum install vim -y 修改ip修改/etc/sysconfig/network-scripts/ifcfg-eth0的内容(如果该文件不存在，先新建) 12345678DEVICE=eth0 #网卡对应的设备别名BOOTPROTO=static #设置为静态IP，staticONBOOT=yesDNS1=114.114.114.114HWADDR=00:07:E9:05:E8:B4 #对应的网卡物理地址，可以不用配置IPADDR=192.168.17.133 #ip地址静态指定NETMASK=255.255.255.0 GATEWAY=192.168.17.2 然后在虚拟机-&gt;设置-&gt;网络适配器中选择自定义VMnet8 可以将原有的ifcfg-enoxxxxxxx文件删除，然后修改grub文件vim /etc/default/grub然后在GRUB_CMDLINE_LINUX原有的参数后面加上&quot;net.ifnames=0 biosdevname=0&quot;，保存退出后，执行grub2-mkconfig -o /boot/grub2/grub.cfg然后重启计算机 添加用户和权限123456789$ useradd apache$ passwd apache$ visudo $ /root$ yyp 安装apache12345678910111213141516171819yum install httpd httpd-devel#开启apache服务systemctl start httpd.service#关闭apache服务systemctl stop httpd.service#设置为开机启动systemctl enable httpd.service#关闭防火墙systemctl stop firewalld.service#开机不启动防火墙systemctl disable firewalld.service#apache默认使用/var/www/html文件夹里的资源，故可以创建一个index.html文件echo apache133 &gt; index.html 安装Nginx使用压缩包安装nginx 切换为root用户 进入/usr/local/src目录下 下载Nginx、openssl、pcre以及zlib 1234wget http://nginx.org/download/nginx-1.12.2.tar.gzwget https://www.openssl.org/source/openssl-fips-2.0.16.tar.gzwget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.40.tar.gzwget http://www.zlib.net/zlib-1.2.11.tar.gz 可能需要先安装c++编译环境 1yum install gcc-c++ 安装openssl 1234tar zxvf openssl-fips-2.0.16.tar.gz cd openssl-fips-2.0.16/./configmake &amp;&amp; make install 安装pcre 1234tar zxvf pcre-8.40.tar.gz cd pcre-8.40/./configuremake &amp;&amp; make install 安装zlib 1234tar zxvf zlib-1.2.11.tar.gz cd zlib-1.2.11/./configuremake &amp;&amp; make install 安装Nginx 1234tar zxvf nginx-1.12.2.tar.gz cd nginx-1.12.2/./configuremake &amp;&amp; make install 启动Nginx 1/usr/local/nginx/sbin/nginx Nginx基本操作 12345678910#启动[root@localhost ~]# /usr/local/nginx/sbin/nginx#停止/重启[root@localhost ~]# /usr/local/nginx/sbin/nginx -s stop(quit、reload)#命令帮助[root@localhost ~]# /usr/local/nginx/sbin/nginx -h#验证配置文件[root@localhost ~]# /usr/local/nginx/sbin/nginx -t#配置文件[root@localhost ~]# vim /usr/local/nginx/conf/nginx.conf 获取Nginx的安装位置 1whereis nginx 修改Nginx的配置文件 12[root@localhost conf]# cd /usr/local/nginx/conf/[root@localhost conf]# vim nginx.conf 在http内添加 1234upstream test.com&#123; server 192.168.17.133:80 weight=5; server 192.168.17.134:80 weight=1;&#125; 在http-&gt;server中的location中添加 12345678location / &#123; proxy_pass http://test.com; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; root html; index index.html index.htm;&#125; 安装rz和sz 1yum install lrzsz 使用yum安装nginx(推荐) 本地yum源中没有我们想要的nginx，那么就需要创建一个/etc/yum.repos.d/nginx.repo的文件，新增一个yum源。 1vim /etc/yum.repos.d/nginx.repo 然后加入如下内容 12345[nginx]name=nginx repobaseurl=http://nginx.org/packages/centos/$releasever/$basearch/gpgcheck=0enabled=1 查询nginx的相关信息并安装 12yum list | grep nginxyum install -y nginx 安装Keepalived安装Keepalived12345wget http://www.keepalived.org/software/keepalived-1.2.24.tar.gztar -zxvf keepalived-1.2.24.tar.gzcd keepalived-1.2.24./configure --prefix=/usr/local/keepalivedmake &amp;&amp; make install 在安装时可能会出现如下错误\!!! OpenSSL is not properly installed on your system. !!!\!!! Can not include OpenSSL headers files.\解决办法：yum -y install openssl-devel 也可以直接使用yum安装 1yum install keepalived 配置Keepalivedkeepalived启动时会从/etc/keepalived目录下查找keepalived.conf配置文件，如果没有找到则使用默认的配置。/etc/keepalived目录安装时默认是没有安装的，需要手动创建。 先备份配置文件 1cp keepalived.conf keepalived.conf.bak 在启动keepalived前先关闭防火墙和selinux 12345678910systemctl stop firewalld.servicesystemctl disable firewalld.servicegetenforce/usr/sbin/sestatus -v#临时关闭setenforce 0#永久关闭vim /etc/selinux/config#将SELINUX=enforcing改为SELINUX=disabled，必须重启才能生效]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Nginx</tag>
        <tag>Keepalived</tag>
      </tags>
  </entry>
</search>
